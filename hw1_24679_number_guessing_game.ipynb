{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0meOXnjNt2cQ"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "THE CODE BELOW IS MODIFIED FROM THE FOLLOWING SOURCE:https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
        "'''\n",
        "\n",
        "# save the final model to file\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainY, epochs=1, batch_size=32, verbose=0)\n",
        "\t# save model\n",
        "\tmodel.save('final_model.h5')\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# load model\n",
        "\tmodel = load_model('final_model.h5')\n",
        "\t# evaluate model on test dataset\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICmalAQQu1y8",
        "outputId": "7a8a87e9-8a57-4763-b551-2fbd15eed94a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 98.610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        " \n",
        "\n",
        "def digit_predict(loc):#the main prediction function\n",
        "  img = load_image(loc)\n",
        "  model=load_model('final_model.h5')\n",
        "  predict_value=model.predict(img)\n",
        "  digit=argmax(predict_value)\n",
        "  return digit\n",
        " \n",
        "\n",
        " \n",
        "# entry point, run the test example\n",
        "loc='/content/ONE.png'\n",
        "ans=digit_predict(loc)\n",
        "ans"
      ],
      "metadata": {
        "id": "M2C9q2yf7Be9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fad7e5-e651-4068-95c6-f6e1664615d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5tfsL-7w6g6",
        "outputId": "023a4c31-4b8e-4deb-8b5c-49365a463657"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.3 MB 28.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 61.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 62.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 270 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 55.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 594 kB 82.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 54.0 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def game(number_img,player_guess):\n",
        "\n",
        "  file_path='/content/'+number_img+'.png' #convert the input to a file path string\n",
        "  img_from_path=cv2.imread(file_path) #read the image from the file path\n",
        "  predicted_num=int(digit_predict(file_path)) #do a prediction for the image \n",
        "\n",
        "  referee_guess=random.randrange(predicted_num*10, (predicted_num*10)+10) #let the referee make a random guess\n",
        "\n",
        "  comp_guess=random.randrange(predicted_num*10, (predicted_num*10)+10) #let the computer make a random guess\n",
        "\n",
        "  diff_comp=np.abs(referee_guess-comp_guess) #measuring how the computers number is from the referee \n",
        "  diff_player=np.abs(referee_guess-int(player_guess)) #measuring how far your number is from the referee\n",
        "\n",
        "  if (diff_comp>diff_player):\n",
        "    s=\"Aww I lost, You won, your guess was closer to the referee. How do you do this,you're really smart at guessing.you could become an expert at guessing games!\"\n",
        "  elif(diff_comp<diff_player):\n",
        "    s=\"Yay I won, my guess is closer! Good job thinking you'd fancy beating me but i proved you wrong.You see, humans can make errors, not me since im trained to play by the rules every time.Better luck next time!\"\n",
        "  else:\n",
        "    s=\"Yay, we both made the same guess, good job partner\"\n",
        "  \n",
        "  return img_from_path,s, referee_guess, comp_guess\n",
        "  \n",
        "\n",
        "# number_img=\"EIGHT\"\n",
        "# player_guess=55\n",
        "# s, referee_guess,comp_guess=game(number_img,player_guess)\n",
        "\n",
        "# print(s,referee_guess, comp_guess, img_from_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jrC0tvLzyml_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    ip1=gr.Textbox(label=\"Enter the number who's pic you want to upload\")\n",
        "    name = [ip1,gr.Textbox(label=\"Type your guess in the range of Num*10 and Num*10+10\") ]\n",
        "    output =[ gr.Image(type=\"pil\",label=\"The Image you chose\"), gr.Textbox(label=\"Decision\"), gr.Textbox(label=\"Referee's Move\"), gr.Textbox(label=\"Computers's Move\")]\n",
        "    greet_btn = gr.Button(\"Play\")\n",
        "    greet_btn.click(fn=game, inputs=name, outputs=output)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "c6hZtNqA1vwq",
        "outputId": "5a4a9ce1-5fef-4391-e263-8f9c53a3ac94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://10846.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://10846.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fce34816b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fce34745320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7fce3509c3d0>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://10846.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}